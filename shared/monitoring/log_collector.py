"""
ðŸ“ DoAi.Me Log Collector
Supabase monitoring_logs í…Œì´ë¸”ì— ë¡œê·¸ ì €ìž¥

ì‚¬ìš© ì˜ˆ:
    from shared.monitoring.log_collector import LogCollector, get_log_collector

    # ì‹±ê¸€í†¤ ì‚¬ìš©
    collector = get_log_collector()
    await collector.log("info", "api", "Request processed", context={"duration": 0.5})

    # ë˜ëŠ” ì§ì ‘ ì¸ìŠ¤í„´ìŠ¤
    collector = LogCollector(source="my-service")
    await collector.info("Service started")
    await collector.error("Connection failed", context={"host": "db.example.com"})
"""

import asyncio
import os
from datetime import datetime, timezone
from enum import Enum
from typing import Any, Dict, List, Optional

try:
    from loguru import logger
except ImportError:
    import logging

    logger = logging.getLogger(__name__)
    logging.basicConfig(level=logging.INFO)


class LogLevel(str, Enum):
    """ë¡œê·¸ ë ˆë²¨"""

    DEBUG = "debug"
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


class LogCollector:
    """
    Supabase monitoring_logs í…Œì´ë¸”ì— ë¡œê·¸ ì €ìž¥

    Features:
    - ë¹„ë™ê¸° ë¡œê·¸ ì €ìž¥
    - ë°°ì¹˜ ì €ìž¥ (ë²„í¼ë§)
    - ë¡œì»¬ ë¡œê±°ì™€ ë™ì‹œ ì¶œë ¥
    - ì‹¤íŒ¨ ì‹œ ë¡œì»¬ ë¡œê·¸ë¡œ í´ë°±
    """

    def __init__(
        self,
        source: str = "api",
        component: Optional[str] = None,
        buffer_size: int = 10,
        auto_flush_seconds: float = 5.0,
    ):
        """
        Args:
            source: ë¡œê·¸ ì†ŒìŠ¤ (api, oob, laixi, node-runner)
            component: ì„¸ë¶€ ì»´í¬ë„ŒíŠ¸ (router, service, etc.)
            buffer_size: ë²„í¼ í¬ê¸° (ì´ ìˆ˜ ë§Œí¼ ëª¨ì´ë©´ flush)
            auto_flush_seconds: ìžë™ flush ê°„ê²© (ì´ˆ)
        """
        self.source = source
        self.component = component
        self.buffer_size = buffer_size
        self.auto_flush_seconds = auto_flush_seconds

        self._buffer: List[Dict[str, Any]] = []
        self._lock = asyncio.Lock()
        self._flush_task: Optional[asyncio.Task] = None
        self._client = None
        self._enabled = True

    def _get_client(self):
        """Supabase í´ë¼ì´ì–¸íŠ¸ lazy ë¡œë”©"""
        if self._client is None:
            try:
                from shared.supabase_client import get_client

                self._client = get_client()
            except Exception as e:
                logger.warning(f"Supabase ì—°ê²° ì‹¤íŒ¨, ë¡œì»¬ ë¡œê¹…ë§Œ ì‚¬ìš©: {e}")
                self._enabled = False
        return self._client

    async def log(
        self,
        level: str,
        source: Optional[str] = None,
        message: str = "",
        component: Optional[str] = None,
        context: Optional[Dict[str, Any]] = None,
        node_id: Optional[str] = None,
        device_serial: Optional[str] = None,
        request_id: Optional[str] = None,
    ) -> Optional[str]:
        """
        ë¡œê·¸ ì €ìž¥

        Args:
            level: ë¡œê·¸ ë ˆë²¨ (debug, info, warning, error, critical)
            source: ë¡œê·¸ ì†ŒìŠ¤ (ë¯¸ì§€ì • ì‹œ ì¸ìŠ¤í„´ìŠ¤ ê¸°ë³¸ê°’)
            message: ë¡œê·¸ ë©”ì‹œì§€
            component: ì„¸ë¶€ ì»´í¬ë„ŒíŠ¸
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (JSON)
            node_id: ê´€ë ¨ ë…¸ë“œ ID
            device_serial: ê´€ë ¨ ë””ë°”ì´ìŠ¤ ì‹œë¦¬ì–¼
            request_id: ìš”ì²­ ID (íŠ¸ë ˆì´ì‹±ìš©)

        Returns:
            ë¡œê·¸ ID (ë²„í¼ë§ ì‹œ None)
        """
        # ë¡œì»¬ ë¡œê±°ì—ë„ ì¶œë ¥
        log_func = getattr(logger, level.lower(), logger.info)
        log_func(f"[{source or self.source}] {message}")

        if not self._enabled:
            return None

        log_entry = {
            "level": level,
            "source": source or self.source,
            "component": component or self.component,
            "message": message,
            "context": context or {},
            "node_id": node_id,
            "device_serial": device_serial,
            "request_id": request_id,
            "created_at": datetime.now(timezone.utc).isoformat(),
        }

        async with self._lock:
            self._buffer.append(log_entry)

            if len(self._buffer) >= self.buffer_size:
                await self._flush_buffer()

        # auto flush íƒœìŠ¤í¬ ì‹œìž‘
        if self._flush_task is None or self._flush_task.done():
            self._flush_task = asyncio.create_task(self._auto_flush())

        return None  # ë²„í¼ë§ ì‹œ ID ë°˜í™˜ ë¶ˆê°€

    async def _flush_buffer(self) -> int:
        """ë²„í¼ë¥¼ Supabaseì— ì €ìž¥"""
        if not self._buffer:
            return 0

        entries = self._buffer.copy()
        self._buffer.clear()

        try:
            client = self._get_client()
            if client is None:
                return 0

            # ë°°ì¹˜ ì‚½ìž…
            result = client.table("monitoring_logs").insert(entries).execute()

            count = len(result.data) if result.data else 0
            logger.debug(f"ë¡œê·¸ {count}ê±´ ì €ìž¥ ì™„ë£Œ")
            return count

        except Exception as e:
            logger.error(f"ë¡œê·¸ ì €ìž¥ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨í•œ ë¡œê·¸ëŠ” ë²„í¼ì— ë‹¤ì‹œ ë„£ê¸° (ìµœëŒ€ ë²„í¼ í¬ê¸°ê¹Œì§€)
            self._buffer = entries[: self.buffer_size] + self._buffer[: self.buffer_size]
            return 0

    async def _auto_flush(self):
        """ìžë™ flush íƒœìŠ¤í¬"""
        await asyncio.sleep(self.auto_flush_seconds)
        async with self._lock:
            await self._flush_buffer()

    async def flush(self) -> int:
        """ìˆ˜ë™ flush"""
        async with self._lock:
            return await self._flush_buffer()

    # íŽ¸ì˜ ë©”ì„œë“œë“¤
    async def debug(
        self,
        message: str,
        context: Optional[Dict] = None,
        **kwargs,
    ) -> Optional[str]:
        """DEBUG ë ˆë²¨ ë¡œê·¸"""
        return await self.log("debug", message=message, context=context, **kwargs)

    async def info(
        self,
        message: str,
        context: Optional[Dict] = None,
        **kwargs,
    ) -> Optional[str]:
        """INFO ë ˆë²¨ ë¡œê·¸"""
        return await self.log("info", message=message, context=context, **kwargs)

    async def warning(
        self,
        message: str,
        context: Optional[Dict] = None,
        **kwargs,
    ) -> Optional[str]:
        """WARNING ë ˆë²¨ ë¡œê·¸"""
        return await self.log("warning", message=message, context=context, **kwargs)

    async def error(
        self,
        message: str,
        context: Optional[Dict] = None,
        **kwargs,
    ) -> Optional[str]:
        """ERROR ë ˆë²¨ ë¡œê·¸"""
        return await self.log("error", message=message, context=context, **kwargs)

    async def critical(
        self,
        message: str,
        context: Optional[Dict] = None,
        **kwargs,
    ) -> Optional[str]:
        """CRITICAL ë ˆë²¨ ë¡œê·¸"""
        return await self.log("critical", message=message, context=context, **kwargs)


# ===========================================
# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
# ===========================================

_collector: Optional[LogCollector] = None


def get_log_collector(source: str = "api") -> LogCollector:
    """ë¡œê·¸ ì»¬ë ‰í„° ì‹±ê¸€í†¤"""
    global _collector

    if _collector is None:
        _collector = LogCollector(source=source)

    return _collector


def reset_log_collector():
    """í…ŒìŠ¤íŠ¸ìš© ë¦¬ì…‹"""
    global _collector
    _collector = None


# ===========================================
# ë¡œê·¸ ê²€ìƒ‰ í•¨ìˆ˜
# ===========================================


async def search_logs(
    level: Optional[str] = None,
    source: Optional[str] = None,
    start_time: Optional[datetime] = None,
    end_time: Optional[datetime] = None,
    search_text: Optional[str] = None,
    limit: int = 100,
    offset: int = 0,
) -> List[Dict[str, Any]]:
    """
    ë¡œê·¸ ê²€ìƒ‰

    Args:
        level: ë¡œê·¸ ë ˆë²¨ í•„í„°
        source: ì†ŒìŠ¤ í•„í„°
        start_time: ì‹œìž‘ ì‹œê°„
        end_time: ì¢…ë£Œ ì‹œê°„
        search_text: ë©”ì‹œì§€ ê²€ìƒ‰ì–´
        limit: ìµœëŒ€ ê²°ê³¼ ìˆ˜
        offset: ì˜¤í”„ì…‹

    Returns:
        ë¡œê·¸ ëª©ë¡
    """
    try:
        from shared.supabase_client import get_client

        client = get_client()

        query = client.table("monitoring_logs").select("*")

        if level:
            query = query.eq("level", level)
        if source:
            query = query.eq("source", source)
        if start_time:
            query = query.gte("created_at", start_time.isoformat())
        if end_time:
            query = query.lte("created_at", end_time.isoformat())
        if search_text:
            query = query.ilike("message", f"%{search_text}%")

        query = query.order("created_at", desc=True).limit(limit).offset(offset)

        result = query.execute()
        return result.data or []

    except Exception as e:
        logger.error(f"ë¡œê·¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []


async def get_log_stats(hours: int = 24) -> Dict[str, Any]:
    """
    ë¡œê·¸ í†µê³„ ì¡°íšŒ

    Args:
        hours: ì¡°íšŒí•  ì‹œê°„ ë²”ìœ„

    Returns:
        ë ˆë²¨ë³„ ë¡œê·¸ ìˆ˜
    """
    try:
        from shared.supabase_client import get_client

        client = get_client()

        # ì‹œê°„ ë²”ìœ„ ê³„ì‚°
        from datetime import timedelta

        start_time = datetime.now(timezone.utc) - timedelta(hours=hours)

        result = (
            client.table("monitoring_logs")
            .select("level")
            .gte("created_at", start_time.isoformat())
            .execute()
        )

        # ë ˆë²¨ë³„ ì§‘ê³„
        stats = {"debug": 0, "info": 0, "warning": 0, "error": 0, "critical": 0, "total": 0}

        for row in result.data or []:
            level = row.get("level", "info")
            if level in stats:
                stats[level] += 1
            stats["total"] += 1

        return stats

    except Exception as e:
        logger.error(f"ë¡œê·¸ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {"error": str(e)}
